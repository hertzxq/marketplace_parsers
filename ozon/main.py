from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium_stealth import stealth
from bs4 import BeautifulSoup
import time
import json
import re
import random


def driver_options():
    options = Options()
    options.add_argument('--disable-blink-features=AutomationControlled')
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option('useAutomationExtension', False)
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--no-sandbox')
    options.add_argument('--window-size=1920,1080')
    options.add_argument('--disable-web-security')
    options.add_argument('--disable-features=IsolateOrigins,site-per-process')
    # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º Chrome –∏ —Ä—É—Å—Å–∫—É—é –ª–æ–∫–∞–ª—å
    options.add_argument(
        'user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
    options.add_argument('--lang=ru-RU')
    options.add_argument('--accept-lang=ru-RU,ru;q=0.9')

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ü–∏–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –∞–Ω—Ç–∏–±–æ—Ç
    prefs = {
        "profile.default_content_setting_values": {
            "notifications": 2
        },
        "profile.managed_default_content_settings": {
            "images": 1
        },
        "intl.accept_languages": "ru-RU,ru"
    }
    options.add_experimental_option("prefs", prefs)

    driver = webdriver.Chrome(options=options)

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≥–µ–æ–ª–æ–∫–∞—Ü–∏—é –Ω–∞ –ú–æ—Å–∫–≤—É —á–µ—Ä–µ–∑ CDP
    print("üìç –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≥–µ–æ–ª–æ–∫–∞—Ü–∏–∏: –ú–æ—Å–∫–≤–∞...")
    try:
        # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –ú–æ—Å–∫–≤—ã: 55.7558¬∞ N, 37.6173¬∞ E
        driver.execute_cdp_cmd('Emulation.setGeolocationOverride', {
            "latitude": 55.7558,
            "longitude": 37.6173,
            "accuracy": 100
        })
        print("‚úÖ –ì–µ–æ–ª–æ–∫–∞—Ü–∏—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: –ú–æ—Å–∫–≤–∞ (55.7558, 37.6173)")
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≥–µ–æ–ª–æ–∫–∞—Ü–∏—é —á–µ—Ä–µ–∑ CDP: {e}")

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —á–∞—Å–æ–≤–æ–π –ø–æ—è—Å –¥–ª—è –ú–æ—Å–∫–≤—ã (Europe/Moscow, UTC+3)
    try:
        driver.execute_cdp_cmd('Emulation.setTimezoneOverride', {
            "timezoneId": "Europe/Moscow"
        })
        print("‚úÖ –ß–∞—Å–æ–≤–æ–π –ø–æ—è—Å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: Europe/Moscow (UTC+3)")
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —á–∞—Å–æ–≤–æ–π –ø–æ—è—Å: {e}")

    # –£–ª—É—á—à–µ–Ω–Ω—ã–π –æ–±—Ö–æ–¥ –¥–µ—Ç–µ–∫—Ü–∏–∏ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏
    driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
        'source': '''
            Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
            Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});
            Object.defineProperty(navigator, 'languages', {get: () => ['ru-RU', 'ru', 'en-US', 'en']});
            Object.defineProperty(navigator, 'geolocation', {
                get: () => ({
                    getCurrentPosition: (success, error) => {
                        success({
                            coords: {
                                latitude: 55.7558,
                                longitude: 37.6173,
                                accuracy: 100
                            },
                            timestamp: Date.now()
                        });
                    }
                })
            });
            window.chrome = {runtime: {}};
        '''
    })

    driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")

    stealth(
        driver,
        languages=["ru-RU", "ru"],
        vendor="Google Inc.",
        platform="Win32",
        webgl_vendor="Intel Inc.",
        renderer="Intel Iris OpenGL Engine",
        fix_hairline=True
    )

    return driver


def driver_scroll(driver, deep_scroll=30):
    """–ü–ª–∞–≤–Ω–∞—è –ø—Ä–æ–∫—Ä—É—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –∏–º–∏—Ç–∞—Ü–∏–µ–π —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è"""
    for i in range(deep_scroll):
        scroll_amount = random.randint(300, 700)
        driver.execute_script(f"window.scrollBy(0, {scroll_amount})")
        time.sleep(random.uniform(0.1, 0.3))

    # –ü—Ä–æ–∫—Ä—É—Ç–∫–∞ –≤–≤–µ—Ä—Ö –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
    driver.execute_script("window.scrollTo(0, 0)")
    time.sleep(0.5)

    # –ü—Ä–æ–∫—Ä—É—Ç–∫–∞ –∫ —ç–ª–µ–º–µ–Ω—Ç—É —Å —Ü–µ–Ω–æ–π
    try:
        driver.execute_script("""
            var priceElement = document.querySelector('[data-widget="webPrice"]');
            if (priceElement) {
                priceElement.scrollIntoView({behavior: 'smooth', block: 'center'});
            }
        """)
        time.sleep(1)
    except:
        pass


def extract_json_ld(soup):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ JSON-LD"""
    scripts = soup.find_all('script', {'type': 'application/ld+json'})
    for script in scripts:
        try:
            data = json.loads(script.string)
            if data.get('@type') == 'Product':
                return data
        except:
            continue
    return None


def wait_for_page_load(driver, timeout=30):
    """–û–∂–∏–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ JavaScript"""
    wait = WebDriverWait(driver, timeout)

    # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ DOM
    wait.until(lambda d: d.execute_script("return document.readyState") == "complete")
    time.sleep(2)

    # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ –≤–∏–¥–∂–µ—Ç–∞ —Å —Ü–µ–Ω–æ–π
    try:
        wait.until(EC.presence_of_element_located(
            (By.CSS_SELECTOR, '[data-widget="webPrice"], [data-widget="webProductHeading"]')))
    except:
        pass

    # –ñ–¥–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è JavaScript
    wait.until(lambda d: d.execute_script("return typeof jQuery !== 'undefined' ? jQuery.active == 0 : true"))
    time.sleep(1)

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    for _ in range(5):
        try:
            driver.execute_script("""
                return document.querySelector('[data-widget="webPrice"]') !== null;
            """)
            time.sleep(0.5)
        except:
            pass


def parse_product(driver, url):
    """–ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ç–æ–≤–∞—Ä–∞ –Ω–∞ Ozon —Å —É—á–µ—Ç–æ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
    print("üåê –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º cookies –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞ –ú–æ—Å–∫–≤—ã –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    try:
        # –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∂–∞–µ–º –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ cookies
        print("üåê –ó–∞–≥—Ä—É–∑–∫–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–µ–≥–∏–æ–Ω–∞...")
        driver.get("https://www.ozon.ru/")
        time.sleep(3)

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–≥–∏–æ–Ω –ú–æ—Å–∫–≤—ã —á–µ—Ä–µ–∑ JavaScript (Ozon –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —ç—Ç–æ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–µ–≥–∏–æ–Ω–∞)
        driver.execute_script("""
            // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–≥–∏–æ–Ω –≤ localStorage
            if (typeof(Storage) !== "undefined") {
                localStorage.setItem('location', '–ú–æ—Å–∫–≤–∞');
                localStorage.setItem('region', '–ú–æ—Å–∫–≤–∞');
                localStorage.setItem('city', '–ú–æ—Å–∫–≤–∞');
                localStorage.setItem('regionId', '1'); // ID –ú–æ—Å–∫–≤—ã –≤ Ozon
            }

            // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤ sessionStorage
            if (typeof(sessionStorage) !== "undefined") {
                sessionStorage.setItem('location', '–ú–æ—Å–∫–≤–∞');
                sessionStorage.setItem('region', '–ú–æ—Å–∫–≤–∞');
            }
        """)

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º cookies –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞ –ú–æ—Å–∫–≤—ã
        # Ozon –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ cookie –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–µ–≥–∏–æ–Ω–∞
        cookies_to_set = [
            {"name": "location", "value": "–ú–æ—Å–∫–≤–∞", "domain": ".ozon.ru", "path": "/"},
            {"name": "region", "value": "–ú–æ—Å–∫–≤–∞", "domain": ".ozon.ru", "path": "/"},
            {"name": "city", "value": "–ú–æ—Å–∫–≤–∞", "domain": ".ozon.ru", "path": "/"},
            {"name": "regionId", "value": "1", "domain": ".ozon.ru", "path": "/"},
            {"name": "ozon_delivery_region", "value": "–ú–æ—Å–∫–≤–∞", "domain": ".ozon.ru", "path": "/"},
            {"name": "ozon_delivery_city", "value": "–ú–æ—Å–∫–≤–∞", "domain": ".ozon.ru", "path": "/"},
        ]

        for cookie in cookies_to_set:
            try:
                driver.add_cookie(cookie)
            except:
                pass

        print("‚úÖ Cookies –∏ localStorage –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞ –ú–æ—Å–∫–≤—ã —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫
        driver.refresh()
        time.sleep(2)

    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å cookies: {e}")

    # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–µ–≥–∏–æ–Ω–∞ –≤ URL, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
    if '?' not in url:
        url_with_region = url + '?location=–ú–æ—Å–∫–≤–∞'
    else:
        url_with_region = url + '&location=–ú–æ—Å–∫–≤–∞'

    # –¢–µ–ø–µ—Ä—å –∑–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ç–æ–≤–∞—Ä–∞
    print(f"üõí –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ç–æ–≤–∞—Ä–∞: {url_with_region}")
    driver.get(url_with_region)

    # –ò–º–∏—Ç–∞—Ü–∏—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è - —Å–ª—É—á–∞–π–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
    time.sleep(random.uniform(3, 6))

    # –û–∂–∏–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    print("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
    wait_for_page_load(driver, timeout=30)

    # –ü—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤—Å–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    print("üìú –ü—Ä–æ–∫—Ä—É—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")
    driver_scroll(driver, 50)

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ –ø—Ä–æ–∫—Ä—É—Ç–∫–∏
    time.sleep(3)

    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Ä–µ–≥–∏–æ–Ω —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    try:
        driver.execute_script("""
            // –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–≥–∏–æ–Ω –µ—â–µ —Ä–∞–∑ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if (typeof(Storage) !== "undefined") {
                localStorage.setItem('location', '–ú–æ—Å–∫–≤–∞');
                localStorage.setItem('region', '–ú–æ—Å–∫–≤–∞');
                localStorage.setItem('city', '–ú–æ—Å–∫–≤–∞');
            }

            // –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∏ –∫–ª–∏–∫–Ω—É—Ç—å –Ω–∞ —Å–µ–ª–µ–∫—Ç–æ—Ä —Ä–µ–≥–∏–æ–Ω–∞, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
            var regionSelector = document.querySelector('[data-widget*="location"], [data-widget*="region"]');
            if (regionSelector) {
                console.log('–ù–∞–π–¥–µ–Ω —Å–µ–ª–µ–∫—Ç–æ—Ä —Ä–µ–≥–∏–æ–Ω–∞');
            }
        """)
    except:
        pass

    # –ñ–¥–µ–º –µ—â–µ –Ω–µ–º–Ω–æ–≥–æ –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ —Ä–µ–≥–∏–æ–Ω–∞
    time.sleep(2)

    # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ü–µ–Ω—É —á–µ—Ä–µ–∑ JavaScript –Ω–∞–ø—Ä—è–º—É—é
    print("üîç –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ JavaScript...")
    js_price = None
    try:
        js_price = driver.execute_script("""
            var priceWidget = document.querySelector('[data-widget="webPrice"]');
            if (priceWidget) {
                var priceText = priceWidget.innerText || priceWidget.textContent;
                return priceText;
            }
            return null;
        """)
        if js_price:
            print(f"üí∞ –¶–µ–Ω–∞ –Ω–∞–π–¥–µ–Ω–∞ —á–µ—Ä–µ–∑ JS: {js_price}")
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ü–µ–Ω—É —á–µ—Ä–µ–∑ JS: {e}")

    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∞–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ HTML
    soup = BeautifulSoup(driver.page_source, 'html.parser')

    product_data = {
        'url': url,
        'title': None,
        'price': None,
        'old_price': None,
        'rating': None,
        'reviews_count': None,
        'questions_count': None,
        'images': [],
        'description': None,
        'full_description': None,
        'characteristics': {},
        'availability': None,
        'brand': None,
        'seller': None,
        'seller_name': None,
        'sku': None,
        'category': None,
        'discount_percent': None,
        'delivery_info': None,
        'warranty': None,
        'country': None,
        'product_id': None
    }

    # 1. –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
    title_selectors = [
        ('h1', {}),
        ('h1', {'data-widget': 'webProductHeading'}),
        ('[data-widget="webProductHeading"] h1', {}),
        ('span', {'class': lambda x: x and 'heading' in str(x).lower() and 'product' in str(x).lower()})
    ]
    for selector, attrs in title_selectors:
        title = soup.find(selector, attrs)
        if title:
            product_data['title'] = title.get_text(strip=True)
            break

    # 2. –¶–µ–Ω–∞ (–∞–∫—Ç—É–∞–ª—å–Ω–∞—è) - —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Å —É—á–µ—Ç–æ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
    # –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ü–µ–Ω—É —á–µ—Ä–µ–∑ Selenium –Ω–∞–ø—Ä—è–º—É—é
    try:
        wait = WebDriverWait(driver, 10)
        # –ò—â–µ–º —Ü–µ–Ω—É —Å Ozon –ö–∞—Ä—Ç–æ–π (–æ–±—ã—á–Ω–æ —ç—Ç–æ –æ—Å–Ω–æ–≤–Ω–∞—è —Ü–µ–Ω–∞)
        price_selectors = [
            '[data-widget="webPrice"]',
            '[data-widget="webPrice"] span',
            '.tsHeadline700XLarge',  # –ö–ª–∞—Å—Å –¥–ª—è –∫—Ä—É–ø–Ω–æ–π —Ü–µ–Ω—ã
            '[class*="price"][class*="current"]'
        ]

        price_found = False
        for selector in price_selectors:
            try:
                price_elements = driver.find_elements(By.CSS_SELECTOR, selector)
                for elem in price_elements:
                    price_text = elem.text
                    if price_text and ('‚ÇΩ' in price_text or any(c.isdigit() for c in price_text)):
                        # –ò—â–µ–º —Ü–µ–Ω—É —Å Ozon –ö–∞—Ä—Ç–æ–π (–æ–±—ã—á–Ω–æ –ø–µ—Ä–≤–∞—è —Ü–µ–Ω–∞)
                        if 'ozon –∫–∞—Ä—Ç' in price_text.lower() or 'ozon –∫–∞—Ä—Ç' not in price_text.lower():
                            price_match = re.search(r'([\d\s]+)',
                                                    price_text.replace('\xa0', ' ').replace('‚ÇΩ', '').replace('\u2009',
                                                                                                             ' '))
                            if price_match:
                                potential_price = price_match.group(1).replace(' ', '').replace('\xa0', '').replace(
                                    '\u2009', '')
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Ä–∞–∑—É–º–Ω–∞—è —Ü–µ–Ω–∞ (–Ω–µ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∞—è –∏–ª–∏ –±–æ–ª—å—à–∞—è)
                                if potential_price and len(potential_price) >= 3:
                                    product_data['price'] = potential_price
                                    print(f"‚úÖ –¶–µ–Ω–∞ –Ω–∞–π–¥–µ–Ω–∞ —á–µ—Ä–µ–∑ Selenium: {product_data['price']} ‚ÇΩ")
                                    price_found = True
                                    break
                if price_found:
                    break
            except:
                continue

        if not price_found:
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ª—é–±—É—é —Ü–µ–Ω—É
            price_elements = driver.find_elements(By.CSS_SELECTOR, '[data-widget="webPrice"]')
            if price_elements:
                price_text = price_elements[0].text
                price_match = re.search(r'([\d\s]+)',
                                        price_text.replace('\xa0', ' ').replace('‚ÇΩ', '').replace('\u2009', ' '))
                if price_match:
                    product_data['price'] = price_match.group(1).replace(' ', '').replace('\xa0', '').replace('\u2009',
                                                                                                              '')
                    print(f"‚úÖ –¶–µ–Ω–∞ –Ω–∞–π–¥–µ–Ω–∞ —á–µ—Ä–µ–∑ Selenium (fallback): {product_data['price']} ‚ÇΩ")
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ü–µ–Ω—É —á–µ—Ä–µ–∑ Selenium: {e}")

    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —á–µ—Ä–µ–∑ Selenium, –∏—Å–ø–æ–ª—å–∑—É–µ–º JS —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    if not product_data['price'] and js_price:
        price_match = re.search(r'([\d\s]+)', js_price.replace('\xa0', ' ').replace('‚ÇΩ', '').replace('\u2009', ' '))
        if price_match:
            product_data['price'] = price_match.group(1).replace(' ', '').replace('\xa0', '').replace('\u2009', '')
            print(f"‚úÖ –¶–µ–Ω–∞ –Ω–∞–π–¥–µ–Ω–∞ —á–µ—Ä–µ–∑ JS: {product_data['price']}")

    # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ –Ω–∞—à–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º BeautifulSoup
    if not product_data['price']:
        price_selectors = [
            ('span', {'data-widget': 'webPrice'}),
            ('div', {'data-widget': 'webPrice'}),
            ('span', {'class': lambda x: x and 'price' in str(x).lower() and 'current' in str(x).lower()}),
            ('span', {'class': lambda x: x and 'tsHeadline' in str(x) and 'price' in str(x).lower()})
        ]
        for tag, attrs in price_selectors:
            price_elem = soup.find(tag, attrs)
            if price_elem:
                price_text = price_elem.get_text(strip=True)
                # –ò—â–µ–º —Ü–µ–Ω—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ "1 227 ‚ÇΩ" –∏–ª–∏ "1227"
                price_match = re.search(r'([\d\s]+)',
                                        price_text.replace('\xa0', ' ').replace('‚ÇΩ', '').replace('\u2009', ' '))
                if price_match:
                    product_data['price'] = price_match.group(1).replace(' ', '').replace('\xa0', '').replace('\u2009',
                                                                                                              '')
                    print(f"‚úÖ –¶–µ–Ω–∞ –Ω–∞–π–¥–µ–Ω–∞ —á–µ—Ä–µ–∑ BeautifulSoup: {product_data['price']}")
                    break

    # 3. –°—Ç–∞—Ä–∞—è —Ü–µ–Ω–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å —Å–∫–∏–¥–∫–∞) - —á–µ—Ä–µ–∑ Selenium
    # –ò—â–µ–º –∑–∞—á–µ—Ä–∫–Ω—É—Ç—ã–µ —Ü–µ–Ω—ã (text-decoration: line-through –∏–ª–∏ –∫–ª–∞—Å—Å—ã —Å old/crossed)
    try:
        # –ò—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å –∑–∞—á–µ—Ä–∫–Ω—É—Ç—ã–º —Ç–µ–∫—Å—Ç–æ–º —á–µ—Ä–µ–∑ CSS
        old_price_elements = driver.find_elements(By.CSS_SELECTOR,
                                                  'span[class*="old"][class*="price"], span[class*="original"][class*="price"], '
                                                  'span[class*="crossed"], [style*="line-through"], [style*="text-decoration: line-through"], '
                                                  's, del, strike, [class*="strikethrough"]')

        old_prices = []
        for elem in old_price_elements:
            old_price_text = elem.text
            if old_price_text:
                old_price_match = re.search(r'([\d\s]+)',
                                            old_price_text.replace('\xa0', ' ').replace('‚ÇΩ', '').replace('\u2009', ' '))
                if old_price_match:
                    potential_price = old_price_match.group(1).replace(' ', '').replace('\xa0', '').replace('\u2009',
                                                                                                            '')
                    if potential_price and len(potential_price) >= 3:
                        try:
                            price_int = int(potential_price)
                            old_prices.append(price_int)
                        except:
                            pass

        # –ë–µ—Ä–µ–º —Å–∞–º—É—é –±–æ–ª—å—à—É—é –∑–∞—á–µ—Ä–∫–Ω—É—Ç—É—é —Ü–µ–Ω—É (–æ–±—ã—á–Ω–æ —ç—Ç–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞)
        if old_prices:
            product_data['old_price'] = str(max(old_prices))
            # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç —Å–∫–∏–¥–∫–∏
            if product_data['price']:
                try:
                    old = int(product_data['old_price'])
                    new = int(product_data['price'])
                    if old > new:
                        discount = int((1 - new / old) * 100)
                        product_data['discount_percent'] = discount
                except:
                    pass
    except Exception as e:
        pass

    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —á–µ—Ä–µ–∑ Selenium, –∏—Å–ø–æ–ª—å–∑—É–µ–º BeautifulSoup
    if not product_data['old_price']:
        # –ò—â–µ–º –∑–∞—á–µ—Ä–∫–Ω—É—Ç—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã (s, del, strike, —ç–ª–µ–º–µ–Ω—Ç—ã —Å line-through)
        old_price_selectors = [
            ('s', {}),
            ('del', {}),
            ('strike', {}),
            ('span', {'class': lambda x: x and 'old' in str(x).lower() and 'price' in str(x).lower()}),
            ('span', {'class': lambda x: x and 'original' in str(x).lower() and 'price' in str(x).lower()}),
            ('span', {'class': lambda x: x and 'crossed' in str(x).lower()}),
            ('span', {'style': lambda x: x and 'line-through' in str(x).lower()})
        ]

        old_prices = []
        for tag, attrs in old_price_selectors:
            old_price = soup.find(tag, attrs)
            if old_price:
                old_price_text = old_price.get_text(strip=True)
                old_price_match = re.search(r'([\d\s]+)',
                                            old_price_text.replace('\xa0', ' ').replace('‚ÇΩ', '').replace('\u2009', ' '))
                if old_price_match:
                    potential_price = old_price_match.group(1).replace(' ', '').replace('\xa0', '').replace('\u2009',
                                                                                                            '')
                    if potential_price and len(potential_price) >= 3:
                        try:
                            price_int = int(potential_price)
                            old_prices.append(price_int)
                        except:
                            pass

        # –ë–µ—Ä–µ–º —Å–∞–º—É—é –±–æ–ª—å—à—É—é –∑–∞—á–µ—Ä–∫–Ω—É—Ç—É—é —Ü–µ–Ω—É
        if old_prices:
            product_data['old_price'] = str(max(old_prices))
            # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç —Å–∫–∏–¥–∫–∏
            if product_data['price']:
                try:
                    old = int(product_data['old_price'])
                    new = int(product_data['price'])
                    if old > new:
                        discount = int((1 - new / old) * 100)
                        product_data['discount_percent'] = discount
                except:
                    pass

    # 4. –†–µ–π—Ç–∏–Ω–≥ –∏ –æ—Ç–∑—ã–≤—ã - —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
    rating_selectors = [
        ('div', {'data-widget': 'webSingleProductScore'}),
        ('div', {'class': lambda x: x and 'rating' in str(x).lower() and 'score' in str(x).lower()}),
        ('span', {'class': lambda x: x and 'rating' in str(x).lower()})
    ]
    for tag, attrs in rating_selectors:
        rating_elem = soup.find(tag, attrs)
        if rating_elem:
            rating_text = rating_elem.get_text(strip=True)
            rating_match = re.search(r'(\d+[.,]?\d*)', rating_text)
            if rating_match:
                product_data['rating'] = rating_match.group(1).replace(',', '.')
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –≤ —Ç–æ–º –∂–µ —ç–ª–µ–º–µ–Ω—Ç–µ
                reviews_match = re.search(r'(\d+[\s\d]*)\s*–æ—Ç–∑—ã–≤', rating_text, re.IGNORECASE)
                if reviews_match:
                    product_data['reviews_count'] = reviews_match.group(1).replace(' ', '').replace('\xa0', '')
                break

    # –ü–æ–∏—Å–∫ –æ—Ç–∑—ã–≤–æ–≤ –æ—Ç–¥–µ–ª—å–Ω–æ
    if not product_data['reviews_count']:
        reviews_selectors = [
            ('a', {'href': lambda x: x and 'reviews' in str(x).lower()}),
            ('div', {'data-widget': 'webSingleProductScore'})
        ]
        for tag, attrs in reviews_selectors:
            reviews = soup.find(tag, attrs)
            if reviews:
                reviews_text = reviews.get_text(strip=True)
                reviews_match = re.search(r'(\d+[\s\d]*)\s*–æ—Ç–∑—ã–≤', reviews_text, re.IGNORECASE)
                if reviews_match:
                    product_data['reviews_count'] = reviews_match.group(1).replace(' ', '').replace('\xa0', '')
                    break

        # –ü–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É –æ—Ç–¥–µ–ª—å–Ω–æ
        if not product_data['reviews_count']:
            reviews_span = soup.find('span', string=lambda text: text and '–æ—Ç–∑—ã–≤' in str(text).lower())
            if reviews_span:
                reviews_text = reviews_span.get_text(strip=True)
                reviews_match = re.search(r'(\d+[\s\d]*)\s*–æ—Ç–∑—ã–≤', reviews_text, re.IGNORECASE)
                if reviews_match:
                    product_data['reviews_count'] = reviews_match.group(1).replace(' ', '').replace('\xa0', '')

    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤
    questions_elem = soup.find('div', {'data-widget': 'webQuestionCount'})
    if questions_elem:
        questions_text = questions_elem.get_text(strip=True)
        questions_match = re.search(r'(\d+[\s\d]*)\s*–≤–æ–ø—Ä–æ—Å', questions_text, re.IGNORECASE)
        if questions_match:
            product_data['questions_count'] = questions_match.group(1).replace(' ', '').replace('\xa0', '')

    # 5. –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–∞ - —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
    # –ò—â–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –¥–æ–º–µ–Ω–æ–º ozone.ru
    all_images = soup.find_all('img')
    seen_images = set()
    for img in all_images:
        src = img.get('src') or img.get('data-src') or img.get('data-lazy-src')
        if src:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL
            if src.startswith('//'):
                src = 'https:' + src
            elif src.startswith('/'):
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—É—Ç–∏
            # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–∞ (–æ–±—ã—á–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç multimedia –∏–ª–∏ ir-*.ozone.ru)
            if ('ozone.ru' in src or 'ir-' in src) and 'multimedia' in src:
                # –£–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∞–∑–º–µ—Ä–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                clean_src = re.sub(r'/wc\d+/', '/wc1000/', src)
                clean_src = re.sub(r'/wc\d+$', '/wc1000', clean_src)
                if clean_src not in seen_images:
                    seen_images.add(clean_src)
                    product_data['images'].append(clean_src)
                    if len(product_data['images']) >= 20:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 20 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                        break

    # 6. –û–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ - —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
    desc_widgets = [
        'webDescription',
        'productDescription',
        'webProductDescription'
    ]
    for widget in desc_widgets:
        desc = soup.find('div', {'data-widget': widget})
        if desc:
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –ø–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
            full_desc = desc.get_text(strip=True, separator='\n')
            if full_desc and len(full_desc) > 50:
                product_data['description'] = full_desc[:500]
                product_data['full_description'] = full_desc
                break

    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –æ–ø–∏—Å–∞–Ω–∏—è
    if not product_data['description']:
        desc_elem = soup.find('div', {'class': lambda x: x and 'description' in str(x).lower()})
        if desc_elem:
            desc_text = desc_elem.get_text(strip=True, separator='\n')
            if desc_text and len(desc_text) > 50:
                product_data['description'] = desc_text[:500]
                product_data['full_description'] = desc_text

    # 7. –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ - —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
    # –ò—â–µ–º –≤ —Ä–∞–∑–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä–∞—Ö
    chars_patterns = [
        ('dl', {'class': lambda x: x and 'characteristic' in str(x).lower()}),
        ('div', {'class': lambda x: x and 'spec' in str(x).lower()}),
        ('table', {'class': lambda x: x and 'spec' in str(x).lower()}),
        ('div', {'data-widget': 'webCharacteristics'})
    ]

    for tag, attrs in chars_patterns:
        chars_section = soup.find(tag, attrs)
        if chars_section:
            # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ dl/dt/dd
            dts = chars_section.find_all('dt')
            dds = chars_section.find_all('dd')
            if dts and dds:
                for dt, dd in zip(dts, dds):
                    key = dt.get_text(strip=True)
                    value = dd.get_text(strip=True)
                    if key and value:
                        product_data['characteristics'][key] = value
            else:
                # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ tr/td
                rows = chars_section.find_all('tr')
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    if len(cells) >= 2:
                        key = cells[0].get_text(strip=True)
                        value = cells[1].get_text(strip=True)
                        if key and value:
                            product_data['characteristics'][key] = value
            if product_data['characteristics']:
                break

    # 8. –ù–∞–ª–∏—á–∏–µ —Ç–æ–≤–∞—Ä–∞
    availability_patterns = [
        ('div', {'class': lambda x: x and ('availability' in str(x).lower() or 'stock' in str(x).lower())})
    ]
    for tag, attrs in availability_patterns:
        availability_elem = soup.find(tag, attrs)
        if availability_elem:
            product_data['availability'] = availability_elem.get_text(strip=True)
            break

    # –ü–æ–∏—Å–∫ –Ω–∞–ª–∏—á–∏—è –ø–æ —Ç–µ–∫—Å—Ç—É
    if not product_data['availability']:
        availability_div = soup.find('div', string=lambda text: text and (
                '–≤ –Ω–∞–ª–∏—á–∏–∏' in str(text).lower() or
                '–Ω–µ—Ç –≤ –Ω–∞–ª–∏—á–∏–∏' in str(text).lower() or
                '–¥–æ—Å—Ç—É–ø–µ–Ω' in str(text).lower()
        ))
        if availability_div:
            product_data['availability'] = availability_div.get_text(strip=True)
        else:
            availability_span = soup.find('span', string=lambda text: text and (
                    '–≤ –Ω–∞–ª–∏—á–∏–∏' in str(text).lower() or
                    '–Ω–µ—Ç –≤ –Ω–∞–ª–∏—á–∏–∏' in str(text).lower()
            ))
            if availability_span:
                product_data['availability'] = availability_span.get_text(strip=True)

    # 9. –ë—Ä–µ–Ω–¥
    brand_patterns = [
        ('a', {'href': lambda x: x and 'brand' in str(x).lower()}),
        ('span', {'class': lambda x: x and 'brand' in str(x).lower()}),
        ('div', {'class': lambda x: x and 'brand' in str(x).lower()})
    ]
    for tag, attrs in brand_patterns:
        brand_elem = soup.find(tag, attrs)
        if brand_elem:
            brand_text = brand_elem.get_text(strip=True)
            if brand_text and len(brand_text) < 100:  # –ë—Ä–µ–Ω–¥ –æ–±—ã—á–Ω–æ –∫–æ—Ä–æ—Ç–∫–∏–π
                product_data['brand'] = brand_text
                break

    # 10. –ü—Ä–æ–¥–∞–≤–µ—Ü
    seller_patterns = [
        ('a', {'href': lambda x: x and 'seller' in str(x).lower()}),
        ('div', {'class': lambda x: x and 'seller' in str(x).lower()}),
        ('span', {'class': lambda x: x and 'seller' in str(x).lower()})
    ]
    for tag, attrs in seller_patterns:
        seller_elem = soup.find(tag, attrs)
        if seller_elem:
            seller_text = seller_elem.get_text(strip=True)
            if seller_text:
                product_data['seller'] = seller_text
                product_data['seller_name'] = seller_text
                break

    # 11. –ê—Ä—Ç–∏–∫—É–ª/SKU
    sku_span = soup.find('span', string=lambda text: text and '–∞—Ä—Ç–∏–∫—É–ª' in str(text).lower())
    if sku_span:
        parent = sku_span.find_parent()
        if parent:
            sku_text = parent.get_text(strip=True)
            sku_match = re.search(r'–∞—Ä—Ç–∏–∫—É–ª[:\s]+([^\s]+)', sku_text, re.IGNORECASE)
            if sku_match:
                product_data['sku'] = sku_match.group(1)

    if not product_data['sku']:
        sku_div = soup.find('div', string=lambda text: text and '–∞—Ä—Ç–∏–∫—É–ª' in str(text).lower())
        if sku_div:
            parent = sku_div.find_parent()
            if parent:
                sku_text = parent.get_text(strip=True)
                sku_match = re.search(r'–∞—Ä—Ç–∏–∫—É–ª[:\s]+([^\s]+)', sku_text, re.IGNORECASE)
                if sku_match:
                    product_data['sku'] = sku_match.group(1)

    # 12. –ö–∞—Ç–µ–≥–æ—Ä–∏—è
    category_elem = soup.find('nav', {'class': lambda x: x and 'breadcrumb' in str(x).lower()})
    if category_elem:
        categories = []
        links = category_elem.find_all('a')
        for link in links:
            cat_text = link.get_text(strip=True)
            if cat_text and cat_text.lower() not in ['–≥–ª–∞–≤–Ω–∞—è', 'home', 'ozon']:
                categories.append(cat_text)
        if categories:
            product_data['category'] = ' > '.join(categories)

    # 13. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ—Å—Ç–∞–≤–∫–µ
    delivery_elem = soup.find('div', string=lambda text: text and (
                '–¥–æ—Å—Ç–∞–≤–∫–∞' in str(text).lower() or '–¥–æ—Å—Ç–∞–≤–∏–º' in str(text).lower()))
    if delivery_elem:
        parent = delivery_elem.find_parent()
        if parent:
            product_data['delivery_info'] = parent.get_text(strip=True)[:200]

    # 14. –ì–∞—Ä–∞–Ω—Ç–∏—è
    warranty_elem = soup.find('div', string=lambda text: text and '–≥–∞—Ä–∞–Ω—Ç–∏—è' in str(text).lower())
    if warranty_elem:
        parent = warranty_elem.find_parent()
        if parent:
            product_data['warranty'] = parent.get_text(strip=True)[:200]

    # 15. –°—Ç—Ä–∞–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞
    country_elem = soup.find('div', string=lambda text: text and '—Å—Ç—Ä–∞–Ω–∞' in str(text).lower())
    if country_elem:
        parent = country_elem.find_parent()
        if parent:
            country_text = parent.get_text(strip=True)
            country_match = re.search(r'—Å—Ç—Ä–∞–Ω–∞[:\s]+([^\n]+)', country_text, re.IGNORECASE)
            if country_match:
                product_data['country'] = country_match.group(1).strip()

    # 16. ID —Ç–æ–≤–∞—Ä–∞ –∏–∑ URL
    id_match = re.search(r'/product/[^/]+-(\d+)/', url)
    if id_match:
        product_data['product_id'] = id_match.group(1)

    # 17. –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON-LD
    json_ld_data = extract_json_ld(soup)
    if json_ld_data:
        if not product_data['title']:
            product_data['title'] = json_ld_data.get('name')
        if not product_data['price']:
            offers = json_ld_data.get('offers', {})
            if isinstance(offers, dict):
                product_data['price'] = offers.get('price')
        if not product_data['rating']:
            rating_obj = json_ld_data.get('aggregateRating', {})
            if isinstance(rating_obj, dict):
                product_data['rating'] = rating_obj.get('ratingValue')
        if not product_data['brand']:
            product_data['brand'] = json_ld_data.get('brand', {}).get('name') if isinstance(json_ld_data.get('brand'),
                                                                                            dict) else json_ld_data.get(
                'brand')
        if not product_data['description']:
            product_data['description'] = json_ld_data.get('description')
            product_data['full_description'] = json_ld_data.get('description')

    return product_data


def print_product_data(data):
    """–ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏—Ç –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–≤–∞—Ä–µ"""
    print("\n" + "=" * 60)
    print("–ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –¢–û–í–ê–†–ï")
    print("=" * 60)

    print(f"\nüì¶ –ù–∞–∑–≤–∞–Ω–∏–µ: {data.get('title', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")

    price_str = f"{data.get('price', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')} ‚ÇΩ"
    if data.get('old_price'):
        price_str += f" (–±—ã–ª–æ {data['old_price']} ‚ÇΩ"
        if data.get('discount_percent'):
            price_str += f", —Å–∫–∏–¥–∫–∞ {data['discount_percent']}%"
        price_str += ")"
    print(f"üí∞ –¶–µ–Ω–∞: {price_str}")

    rating_str = data.get('rating', '–ù–µ —É–∫–∞–∑–∞–Ω')
    if data.get('reviews_count'):
        rating_str += f" ({data['reviews_count']} –æ—Ç–∑—ã–≤–æ–≤)"
    if data.get('questions_count'):
        rating_str += f", {data['questions_count']} –≤–æ–ø—Ä–æ—Å–æ–≤"
    print(f"‚≠ê –†–µ–π—Ç–∏–Ω–≥: {rating_str}")

    print(f"üìç –ù–∞–ª–∏—á–∏–µ: {data.get('availability', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")

    if data.get('brand'):
        print(f"üè∑Ô∏è  –ë—Ä–µ–Ω–¥: {data['brand']}")

    if data.get('seller') or data.get('seller_name'):
        print(f"üè™ –ü—Ä–æ–¥–∞–≤–µ—Ü: {data.get('seller') or data.get('seller_name')}")

    if data.get('sku'):
        print(f"üî¢ –ê—Ä—Ç–∏–∫—É–ª: {data['sku']}")

    if data.get('product_id'):
        print(f"üÜî ID —Ç–æ–≤–∞—Ä–∞: {data['product_id']}")

    if data.get('category'):
        print(f"üìÇ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {data['category']}")

    if data.get('country'):
        print(f"üåç –°—Ç—Ä–∞–Ω–∞: {data['country']}")

    if data.get('images'):
        print(f"\nüñºÔ∏è  –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(data['images'])}")
        print(f"   –ü–µ—Ä–≤–æ–µ: {data['images'][0][:80]}...")

    if data.get('description'):
        print(f"\nüìù –û–ø–∏—Å–∞–Ω–∏–µ: {data['description'][:200]}...")
        if data.get('full_description') and len(data['full_description']) > 200:
            print(f"   (–ü–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {len(data['full_description'])} —Å–∏–º–≤–æ–ª–æ–≤)")

    if data.get('characteristics'):
        print(f"\nüìã –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ ({len(data['characteristics'])} —à—Ç.):")
        for key, value in list(data['characteristics'].items())[:10]:
            print(f"   ‚Ä¢ {key}: {value}")
        if len(data['characteristics']) > 10:
            print(f"   ... –∏ –µ—â–µ {len(data['characteristics']) - 10}")

    if data.get('delivery_info'):
        print(f"\nüöö –î–æ—Å—Ç–∞–≤–∫–∞: {data['delivery_info'][:150]}...")

    if data.get('warranty'):
        print(f"\nüõ°Ô∏è  –ì–∞—Ä–∞–Ω—Ç–∏—è: {data['warranty'][:150]}...")

    print("\n" + "=" * 60 + "\n")


if __name__ == "__main__":
    driver = driver_options()

    try:
        url = "https://www.ozon.ru/product/unison-novogodniy-komplekt-postelnogo-belya-byaz-2h-spalnyy-navolochki-70h70-baker-street-773197367/"

        print("üîç –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ç–æ–≤–∞—Ä–∞...")
        product_data = parse_product(driver, url)

        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        print_product_data(product_data)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
        with open('product_data.json', 'w', encoding='utf-8') as f:
            json.dump(product_data, f, ensure_ascii=False, indent=2)
        print("‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ product_data.json")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback

        traceback.print_exc()

    finally:
        driver.quit()
        print("\n‚úÖ –ë—Ä–∞—É–∑–µ—Ä –∑–∞–∫—Ä—ã—Ç")